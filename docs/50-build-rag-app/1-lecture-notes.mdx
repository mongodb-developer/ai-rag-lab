# ðŸ“˜ Lecture notes

In this workshop, we are generating LLM responses via our AI model proxy so that you can easily run the lab without having to obtain any API keys.

However, if you would like to learn more about the APIs for different LLM providers, refer to their documentation:

* [OpenAI](https://platform.openai.com/docs/api-reference/chat)

* [Gemini by Google](https://ai.google.dev/gemini-api/docs/text-generation)

* [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started-api-keys.html)